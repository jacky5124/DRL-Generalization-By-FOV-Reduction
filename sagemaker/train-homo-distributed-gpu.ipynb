{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Amazon SageMaker Notebook for ProcGen Starter Kit with homogeneous scaling of multiple GPU instances "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import yaml\n",
    "\n",
    "import sagemaker\n",
    "from sagemaker.rl import RLEstimator, RLToolkit, RLFramework\n",
    "import boto3\n",
    "\n",
    "from IPython.display import HTML, Markdown\n",
    "from source.common.docker_utils import build_and_push_docker_image\n",
    "from source.common.markdown_helper import generate_help_for_s3_endpoint_permissions, create_s3_endpoint_manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(\"config\", \"sagemaker_config.yaml\")) as f:\n",
    "    sagemaker_config = yaml.safe_load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Amazon SageMaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm_session = sagemaker.session.Session()\n",
    "s3_bucket = sagemaker_config[\"S3_BUCKET\"]\n",
    "\n",
    "s3_output_path = 's3://{}/'.format(s3_bucket)\n",
    "print(\"S3 bucket path: {}\".format(s3_output_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_name_prefix = 'sm-ray-gpu-dist-procgen'\n",
    "\n",
    "role = sagemaker.get_execution_role()\n",
    "print(role)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note that `local_mode = True` does not work with heterogeneous scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instance_type = sagemaker_config[\"GPU_TRAINING_INSTANCE\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configure the framework you want to use\n",
    "\n",
    "Set `framework` to `\"tf\"` or `\"torch\"` for tensorflow or pytorch respectively.\n",
    "\n",
    "You will also have to edit your entry point i.e., `train-sagemaker-distributed-gpu.py` with the configuration parameter `\"use_pytorch\"` to match the framework that you have selected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "framework = \"tf\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train your homogeneous scaling job here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Edit the training code\n",
    "\n",
    "The training code is written in the file `train-sagemaker-distributed-gpu.py` which is uploaded in the /source directory.\n",
    "\n",
    "*Note that ray will automatically set `\"ray_num_cpus\"` and `\"ray_num_gpus\"` in `_get_ray_config`*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pygmentize source/train-sagemaker-distributed-gpu.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the RL model using the Python SDK Script mode\n",
    "\n",
    "When using SageMaker for distributed training, you can select a GPU or CPU instance. The RLEstimator is used for training RL jobs.\n",
    "\n",
    "1. Specify the source directory where the environment, presets and training code is uploaded.\n",
    "2. Specify the entry point as the training code\n",
    "3. Specify the image (CPU or GPU) to be used for the training environment.\n",
    "4. Define the training parameters such as the instance count, job name, S3 path for output and job name.\n",
    "5. Define the metrics definitions that you are interested in capturing in your logs. These can also be visualized in CloudWatch and SageMaker Notebooks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GPU docker image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Build GPU image\n",
    "gpu_repository_short_name = \"sagemaker-procgen-ray-%s\" % \"gpu\"\n",
    "docker_build_args = {\n",
    "    'CPU_OR_GPU': \"gpu\", \n",
    "    'AWS_REGION': boto3.Session().region_name,\n",
    "    'FRAMEWORK': framework\n",
    "}\n",
    "image_name = build_and_push_docker_image(gpu_repository_short_name, build_args=docker_build_args)\n",
    "print(\"Using GPU ECR image %s\" % image_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_definitions =  [\n",
    "    {'Name': 'training_iteration', 'Regex': 'training_iteration: ([-+]?[0-9]*[.]?[0-9]+([eE][-+]?[0-9]+)?)'}, \n",
    "    {'Name': 'episodes_total', 'Regex': 'episodes_total: ([-+]?[0-9]*[.]?[0-9]+([eE][-+]?[0-9]+)?)'}, \n",
    "    {'Name': 'num_steps_trained', 'Regex': 'num_steps_trained: ([-+]?[0-9]*[.]?[0-9]+([eE][-+]?[0-9]+)?)'}, \n",
    "    {'Name': 'timesteps_total', 'Regex': 'timesteps_total: ([-+]?[0-9]*[.]?[0-9]+([eE][-+]?[0-9]+)?)'},\n",
    "    {'Name': 'training_iteration', 'Regex': 'training_iteration: ([-+]?[0-9]*[.]?[0-9]+([eE][-+]?[0-9]+)?)'},\n",
    "\n",
    "    {'Name': 'episode_reward_max', 'Regex': 'episode_reward_max: ([-+]?[0-9]*[.]?[0-9]+([eE][-+]?[0-9]+)?)'}, \n",
    "    {'Name': 'episode_reward_mean', 'Regex': 'episode_reward_mean: ([-+]?[0-9]*[.]?[0-9]+([eE][-+]?[0-9]+)?)'}, \n",
    "    {'Name': 'episode_reward_min', 'Regex': 'episode_reward_min: ([-+]?[0-9]*[.]?[0-9]+([eE][-+]?[0-9]+)?)'},\n",
    "] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ray homogeneous scaling - Specify `train_instance_count` > 1\n",
    "\n",
    "Homogeneous scaling allows us to use multiple instances of the same type.\n",
    "\n",
    "Spot instances are unused EC2 instances that could be used at 90% discount compared to On-Demand prices (more information about spot instances can be found [here](https://aws.amazon.com/ec2/spot/?cards.sort-by=item.additionalFields.startDateTime&cards.sort-order=asc) and [here](https://docs.aws.amazon.com/sagemaker/latest/dg/model-managed-spot-training.html))\n",
    "\n",
    "To use spot instances, set `train_use_spot_instances = True`. To use On-Demand instances, `train_use_spot_instances = False`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_instance_count = 2\n",
    "train_use_spot_instances = False\n",
    "\n",
    "# Select which procgen environments to run in `envs_to_run`\n",
    "'''\n",
    "envs_to_run = [\"coinrun\", \"bigfish\", \"bossfight\", \"caveflyer\",\n",
    "               \"chaser\", \"climber\",  \"dodgeball\",\n",
    "               \"fruitbot\", \"heist\", \"jumper\", \"leaper\", \"maze\",\n",
    "               \"miner\", \"ninja\", \"plunder\", \"starpilot\"]\n",
    "'''\n",
    "\n",
    "envs_to_run = [\"coinrun\"]\n",
    "\n",
    "for env in envs_to_run:\n",
    "    if train_use_spot_instances:\n",
    "        print('*** Using spot instances ... ')\n",
    "        job_name = 'sm-ray-dist-procgen-spot-' + time.strftime(\"%Y-%m-%d-%H-%M-%S\", time.gmtime()) + \"-\" + env\n",
    "        checkpoint_s3_uri = 's3://{}/sagemaker-procgen/checkpoints/{}'.format(s3_bucket, job_name)\n",
    "        training_params = {\"train_use_spot_instances\": True,\n",
    "                           \"train_max_run\": 3600 * 5,\n",
    "                           \"train_max_wait\": 7200 * 5,\n",
    "                           \"checkpoint_s3_uri\": checkpoint_s3_uri\n",
    "                          }\n",
    "        hyperparameters = {\n",
    "            \"rl.training.upload_dir\": checkpoint_s3_uri, #Necessary for syncing between spot instances\n",
    "            \"rl.training.config.env_config.env_name\": env,\n",
    "        }\n",
    "    else:\n",
    "        training_params = {\"base_job_name\": job_name_prefix + \"-\" + env}\n",
    "        hyperparameters = {\n",
    "            #\"rl.training.upload_dir\": s3_output_path + \"/tensorboard_sync\", # Uncomment to view tensorboard\n",
    "            \"rl.training.config.env_config.env_name\": env,\n",
    "        }\n",
    "\n",
    "    # Defining the RLEstimator\n",
    "    estimator = RLEstimator(entry_point=\"train-sagemaker-distributed-gpu.py\",\n",
    "                            source_dir='source',\n",
    "                            dependencies=[\"source/utils\", \"source/common/\", \"neurips2020-procgen-starter-kit/\"],\n",
    "                            image_uri=image_name,\n",
    "                            role=role,\n",
    "                            instance_type=instance_type,\n",
    "                            instance_count=train_instance_count,\n",
    "                            output_path=s3_output_path,\n",
    "                            metric_definitions=metric_definitions,\n",
    "                            hyperparameters=hyperparameters,\n",
    "                            **training_params\n",
    "                        )\n",
    "    if train_use_spot_instances:\n",
    "        estimator.fit(job_name=job_name, wait=False)\n",
    "    else:\n",
    "        estimator.fit(wait=False)\n",
    "    \n",
    "    print(' ')\n",
    "    print(estimator.latest_training_job.job_name)\n",
    "    print('type=', instance_type, 'count=', train_instance_count )\n",
    "    print(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow2_p36",
   "language": "python",
   "name": "conda_tensorflow2_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
