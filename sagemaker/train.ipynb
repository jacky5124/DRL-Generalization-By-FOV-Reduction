{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Amazon SageMaker Notebook for ProcGen Starter Kit with Single Instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "\n",
    "import sagemaker\n",
    "from sagemaker.rl import RLEstimator, RLToolkit, RLFramework\n",
    "import boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(\"config\", \"sagemaker_config.yaml\")) as f:\n",
    "    sagemaker_config = yaml.safe_load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Amazon SageMaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm_session = sagemaker.session.Session()\n",
    "s3_bucket = sagemaker_config[\"S3_BUCKET\"]\n",
    "\n",
    "s3_output_path = 's3://{}/'.format(s3_bucket)\n",
    "print(\"S3 bucket path: {}\".format(s3_output_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_name_prefix = 'sm-ray-procgen'\n",
    "\n",
    "role = sagemaker.get_execution_role()\n",
    "print(role)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure training instance type and computational resources\n",
    "\n",
    "By default (`local_mode=False`) launch a separate instance for training and debug using the AWS CloudWatch to monitor the logs for the training instance. \n",
    "If you want to train on the same instance as your notebook for quick debugging, then set `local_mode=True`. \n",
    "\n",
    "The recommended instances include with cost per hour as of September, 1, 2020 are:\n",
    "* `ml.c5.4xlarge` $0.952 per hour (16 vCPU)\n",
    "\n",
    "* `ml.g4dn.4xlarge` $1.686 per hour (1 GPU, 16 vCPU)\n",
    "\n",
    "* `ml.p3.2xlarge` $4.284 per hour (1 GPU, 8 vCPU)\n",
    "\n",
    "After you choose your instance type, make sure the edit the resources in `source\\train-sagemaker.py`. For example, with `ml.p3.2xlarge`, you have 1 GPU and 8 vCPUs. The corresponding resources in `source\\train-sagemaker.py` should be set as for `ray` as `\n",
    "\n",
    "```\n",
    "    def _get_ray_config(self):\n",
    "        return {\n",
    "            \"ray_num_cpus\": 8, # adjust based on selected instance type\n",
    "            \"ray_num_gpus\": 1,\n",
    "            \"eager\": False,\n",
    "             \"v\": True, # requried for CW to catch the progress\n",
    "        }\n",
    "``` \n",
    "and for `rrlib` need to use 1 vCPU for driver (\"num_workers\": 7) and 1 GPU (\"num_gpus\": 1) for policy training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change local_mode to True if you want to do local training within this Notebook instance\n",
    "# Otherwise, we'll spin-up a SageMaker training instance to handle the training\n",
    "\n",
    "local_mode = False\n",
    "\n",
    "if local_mode:\n",
    "    instance_type = 'local'\n",
    "else:\n",
    "    instance_type = sagemaker_config[\"CPU_TRAINING_INSTANCE\"]\n",
    "    \n",
    "# If training locally, do some Docker housekeeping..\n",
    "if local_mode:\n",
    "    !/bin/bash source/common/setup.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configure the framework you want to use\n",
    "\n",
    "Set `framework` to `\"tf\"` or `\"torch\"` for tensorflow or pytorch respectively.\n",
    "\n",
    "You will also have to edit your entry point i.e., `train-sagemaker.py` with the configuration parameter `\"use_pytorch\"` to match the framework that you have selected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "framework = \"tf\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train your model here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Edit the training code\n",
    "\n",
    "The training code is written in the file `train-sagemaker.py` which is uploaded in the /source directory.\n",
    "\n",
    "#### *Warning: Confirm that the GPU and CPU resources are configured correctly for your instance type as described above.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pygmentize source/train-sagemaker.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the RL model using the Python SDK Script mode\n",
    "\n",
    "If you are using local mode, the training will run on the notebook instance. \n",
    "\n",
    "When using SageMaker for training, you can select a GPU or CPU instance. The RLEstimator is used for training RL jobs.\n",
    "\n",
    "1. Specify the source directory where the environment, presets and training code is uploaded.\n",
    "2. Specify the entry point as the training code\n",
    "3. Specify the custom image to be used for the training environment.\n",
    "4. Define the training parameters such as the instance count, job name, S3 path for output and job name.\n",
    "5. Define the metrics definitions that you are interested in capturing in your logs. These can also be visualized in CloudWatch and SageMaker Notebooks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*[Choose](https://github.com/aws/sagemaker-rl-container#rl-images-provided-by-sagemaker) which docker image to use based on the instance type.* \n",
    "For this notebook, it has to be a container with Ray 0.8.5 and TensorFlow 2.1.0 to be consistent with the AICrowd ProcGen starter kit. \n",
    "\n",
    "If you prefer to use PyTorch, it is recommended to update your notebook kernel to `conda_pytorch_p36`. You would need to substitute for the corresponding container listed on Amazon SageMaker Reinforcement Learning documentation. In addition, you will need to ensure your starter kit is modified to train using PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpu_or_gpu = 'gpu' if instance_type.startswith(('ml.p', 'ml.g')) else 'cpu'\n",
    "aws_region = boto3.Session().region_name\n",
    "\n",
    "# Use Tensorflow 2 by default\n",
    "custom_image_name = \"462105765813.dkr.ecr.{}.amazonaws.com/sagemaker-rl-ray-container:ray-0.8.5-{}-{}-py36\".format(aws_region, framework, cpu_or_gpu)\n",
    "custom_image_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You need to define metrics to be displayed in the logs. The challenge has requirements on the number of steps and uses mean episode reward to rank various solutions. For details, refer to the AICrowd challange website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_definitions =  [\n",
    "    {'Name': 'training_iteration', 'Regex': 'training_iteration: ([-+]?[0-9]*[.]?[0-9]+([eE][-+]?[0-9]+)?)'}, \n",
    "    {'Name': 'episodes_total', 'Regex': 'episodes_total: ([-+]?[0-9]*[.]?[0-9]+([eE][-+]?[0-9]+)?)'}, \n",
    "    {'Name': 'num_steps_trained', 'Regex': 'num_steps_trained: ([-+]?[0-9]*[.]?[0-9]+([eE][-+]?[0-9]+)?)'}, \n",
    "    {'Name': 'timesteps_total', 'Regex': 'timesteps_total: ([-+]?[0-9]*[.]?[0-9]+([eE][-+]?[0-9]+)?)'},\n",
    "    {'Name': 'training_iteration', 'Regex': 'training_iteration: ([-+]?[0-9]*[.]?[0-9]+([eE][-+]?[0-9]+)?)'},\n",
    "\n",
    "    {'Name': 'episode_reward_max', 'Regex': 'episode_reward_max: ([-+]?[0-9]*[.]?[0-9]+([eE][-+]?[0-9]+)?)'}, \n",
    "    {'Name': 'episode_reward_mean', 'Regex': 'episode_reward_mean: ([-+]?[0-9]*[.]?[0-9]+([eE][-+]?[0-9]+)?)'}, \n",
    "    {'Name': 'episode_reward_min', 'Regex': 'episode_reward_min: ([-+]?[0-9]*[.]?[0-9]+([eE][-+]?[0-9]+)?)'},\n",
    "] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the RL estimator\n",
    "\n",
    "There are 16 environments to choose from. You can run the RL estimator on multiple environments by proving a list of environments as well. The RL estimator will start the training job. This will take longer compared to the above cells, be patient. You can monitor the status of your training job from the console as well, go to Amazon SageMaker > Training jobs. The most recent job will be at the top."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select which procgen environments to run in `envs_to_run`\n",
    "'''\n",
    "envs_to_run = [\"coinrun\", \"bigfish\", \"bossfight\", \"caveflyer\",\n",
    "               \"chaser\", \"climber\", \"coinrun\", \"dodgeball\",\n",
    "               \"fruitbot\", \"heist\", \"jumper\", \"leaper\", \"maze\",\n",
    "               \"miner\", \"ninja\", \"plunder\", \"starpilot\"]\n",
    "'''\n",
    "\n",
    "envs_to_run = [\"coinrun\", \"bigfish\", \"bossfight\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for env in envs_to_run:\n",
    "    estimator = RLEstimator(entry_point=\"train-sagemaker.py\",\n",
    "                            source_dir='source',\n",
    "                            dependencies=[\"source/utils\", \"source/common/\", \"neurips2020-procgen-starter-kit/\"],\n",
    "                            image_uri=custom_image_name,\n",
    "                            role=role,\n",
    "                            instance_type=instance_type,\n",
    "                            instance_count=1,\n",
    "                            output_path=s3_output_path,\n",
    "                            base_job_name=job_name_prefix + \"-\" + env,\n",
    "                            metric_definitions=metric_definitions,\n",
    "                            debugger_hook_config=False,\n",
    "                            hyperparameters={\n",
    "                                #\"rl.training.upload_dir\": s3_output_path,\n",
    "                                \"rl.training.config.env_config.env_name\": env,\n",
    "                            }\n",
    "                        )\n",
    "\n",
    "    estimator.fit(wait=False)\n",
    "    \n",
    "    print(estimator.latest_training_job.job_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### WAAAITTTTT... not more than 2 hours "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize algorithm metrics for training\n",
    "\n",
    "There are several options to visualize algorithm metrics. A detailed blog can be found [here](https://aws.amazon.com/blogs/machine-learning/easily-monitor-and-visualize-metrics-while-training-models-on-amazon-sagemaker/).\n",
    "\n",
    "\n",
    "Option 1 (Amazon CloudWatch): You can go to the [Amazon CloudWatch](https://aws.amazon.com/cloudwatch/) metrics dashboard from your account to monitor and visualize the algorithm metrics as well as track the GPU and CPU usage. The training jobs details page has a direct link to the Amazon CloudWatch metrics dashboard for the metrics emitted by the training algorithm.\n",
    "\n",
    "Option 2 (Amazon SageMaker Python SDK API): You can also visualize the metrics inline in your Amazon SageMaker Jupyter notebooks using the Amazon SageMaker Python SDK APIs. Please, refer to the section titled *Visualize algorithm metrics for training* in `train.ipynb`.\n",
    "\n",
    "Option 3 (Tensorboard): You can also use Ray Tune's integrated Tensorboard by specifying the output directory of your results. It is recommended to set `upload_dir` to a Amazon S3 URI and Tune will automatically sync every 5 miniutes. You can thus visualize your experiment by running the following command on your local laptop:\n",
    "\n",
    "`\n",
    "$AWS_REGION=your-aws-region tensorboard --logdir s3://destination_s3_path --host localhost --port 6006\n",
    "`\n",
    "\n",
    "Check out `train-homo-distributed-cpu.ipynb` for an example of setting `upload_dir`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Option 2: Plot metrics using Amazon SageMaker Python SDK API\n",
    "\n",
    "You need to wait for the training job to allocate computational resources before viewing the logs. \n",
    "\n",
    "*Note: If you get a warning that the logs do not exist, wait for a few minutes and re-run the cell.*\n",
    "\n",
    "*Note 2: If you are getting an import error from Tensorflow, open a terminal and type `source activate tensorflow2_p36`*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For usage, refer to https://sagemaker.readthedocs.io/en/stable/api/training/analytics.html#\n",
    "from sagemaker.analytics import TrainingJobAnalytics\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from source.utils.inference import get_latest_sagemaker_training_job\n",
    "\n",
    "# Get last training job_names\n",
    "eval_training_jobs = [get_latest_sagemaker_training_job(name_contains=\"{}-{}\".format(\n",
    "    job_name_prefix, env)) for env in envs_to_run]\n",
    "\n",
    "for training_job_name, env in zip(eval_training_jobs, envs_to_run):\n",
    "    metric_names = ['episode_reward_mean', 'timesteps_total']\n",
    "\n",
    "    # download the metrics on cloudwatch\n",
    "    metrics_dataframe = TrainingJobAnalytics(training_job_name=training_job_name, metric_names=metric_names).dataframe()\n",
    "\n",
    "    # pivot to get the metrics\n",
    "    metrics_dataframe= metrics_dataframe.pivot(index='timestamp', columns='metric_name', values='value')\n",
    "    \n",
    "    fig = plt.figure()\n",
    "    ax = metrics_dataframe.plot(kind='line', figsize=(12, 5), x='timesteps_total', y='episode_reward_mean', style='b.', legend=False)\n",
    "    ax.set_ylabel('Episode Reward Mean')\n",
    "    ax.set_xlabel('Timesteps')\n",
    "    ax.set_title(env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rollout the model\n",
    "\n",
    "### Note that the following evaluation requries that at least one training job has completed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gym\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "\n",
    "import ray\n",
    "from ray.tune.registry import get_trainable_cls\n",
    "from ray.rllib.models import ModelCatalog\n",
    "\n",
    "from source.custom.envs.procgen_env_wrapper import ProcgenEnvWrapper\n",
    "from source.custom.models.my_vision_network import MyVisionNetwork\n",
    "from source.utils.inference import get_model_config, get_latest_sagemaker_training_job\n",
    "from source.utils.inference import download_ray_checkpoint\n",
    "from source.utils.inference import rollout\n",
    "\n",
    "ray.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = \"PPO\"\n",
    "rollout_env = \"coinrun\"\n",
    "num_steps = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can choose to use the lastest training job or\n",
    "# input the name of your previously trained job\n",
    "latest_training_job = get_latest_sagemaker_training_job(name_contains=\"{}-{}\".format(\n",
    "    job_name_prefix, rollout_env))\n",
    "# latest_training_job = <name of your training job>\n",
    "print(\"Rolling out training job {}\".format(latest_training_job))\n",
    "\n",
    "checkpoint_dir = \"checkpoint\"\n",
    "if not os.path.isdir(checkpoint_dir):\n",
    "    os.mkdir(checkpoint_dir)\n",
    "last_checkpoint_num = download_ray_checkpoint(checkpoint_dir, s3_bucket, latest_training_job)\n",
    "\n",
    "# Print the parameters in the model\n",
    "!cat $checkpoint_dir/params.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You must register all agents, algorithms, models, and preprocessors that you defined in the entry-point.\n",
    "For example, model could be registed like `ModelCatalog.register_custom_model(\"my_vision_network\", MyVisionNetwork)`, custom agents could be registered with `ray.registry.register_trainable`, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls = get_trainable_cls(run)\n",
    "ModelCatalog.register_custom_model(\"my_vision_network\", MyVisionNetwork)\n",
    "config = get_model_config()\n",
    "agent = cls(config=config)\n",
    "checkpoint = os.path.join(\"checkpoint\", \"checkpoint-{}\".format(last_checkpoint_num))\n",
    "agent.restore(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb_array = rollout(agent, \"procgen:procgen-{}-v0\".format(rollout_env),\n",
    "                    num_steps, no_render=False)\n",
    "img = plt.imshow(rgb_array[0])\n",
    "plt.axis('off')\n",
    "for arr in rgb_array[1:]:\n",
    "    img.set_data(arr)\n",
    "    display.display(plt.gcf())\n",
    "    display.clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ray.shutdown()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow2_p36",
   "language": "python",
   "name": "conda_tensorflow2_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
